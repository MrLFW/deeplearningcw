{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/opt/anaconda3/envs/cs3am/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/luke/opt/anaconda3/envs/cs3am/lib/python3.11/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images and labels...\n",
      "Splitting data into training and testing sets...\n",
      "x_train shape: (6941, 224, 224, 3)\n",
      "y_train shape: (6941,)\n",
      "x_test shape: (1736, 224, 224, 3)\n",
      "y_test shape: (1736,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_addons' has no attribute 'vision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Load the pre-trained ViT model from TensorFlow Addons\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m vit_model \u001b[38;5;241m=\u001b[39m \u001b[43mtfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mVisionTransformer(\n\u001b[1;32m     32\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m,\n\u001b[1;32m     33\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     34\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m     35\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m     36\u001b[0m     mlp_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3072\u001b[39m,\n\u001b[1;32m     37\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(class_names),\n\u001b[1;32m     38\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[1;32m     42\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(img_height, img_width, \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_addons' has no attribute 'vision'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "\n",
    "# Load images and labels\n",
    "directory = \"caltech-101/101_ObjectCategories\"\n",
    "img_height = 224  # ViT models typically use 224x224 images\n",
    "img_width = 224\n",
    "\n",
    "# Assuming load_images_and_labels is defined in data_loader.py\n",
    "from data_loader import load_images_and_labels\n",
    "\n",
    "print(\"Loading images and labels...\")\n",
    "images, labels, class_names = load_images_and_labels(directory, img_height, img_width)\n",
    "\n",
    "# Normalize the images\n",
    "images = images / 255.0\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Load the pre-trained ViT model from TensorFlow Addons\n",
    "# vit_model = tfa.vision.models.VisionTransformer(\n",
    "vit_model = tfa.(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_layers=12,\n",
    "    num_heads=12,\n",
    "    mlp_dim=3072,\n",
    "    num_classes=len(class_names),\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "outputs = vit_model(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define a callback to estimate training time\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2, callbacks=[time_callback])\n",
    "\n",
    "# Estimate training time\n",
    "average_epoch_time = np.mean(time_callback.times)\n",
    "print(f\"Average epoch time: {average_epoch_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs3am",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
